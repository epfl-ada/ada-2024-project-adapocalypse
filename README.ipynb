{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"MADAME\" - Studying women representation through movie director’s lens \n",
    "\n",
    "### Abstract\n",
    "\n",
    "\"What do we do now?\" : this famous movie quote embodies how much women are discredited and set aside in cinema, often reduced to their appearance, or defined by their relationships with men. \n",
    "The MADAME project explores the dynamics of female representation in cinema, focusing on how the gender of a movie director influences the portrayal of women. By examining movie genres, character tropes, plot emotions and success, the project investigates how different male and female movie directors depict women. Through an in-depth analysis of plot summaries and character attributes, MADAME project identifies trends in gender representation, for both male and female directed movies. Readers will follow the story of Madame, who leads the analysis, uncovering insights and sparking discussions on the way male and female directors actually represent women in movies. The ultimate goal of our work is to question the rooted stereotypes in film industry to advocate for more inclusive and diverse narratives in film.\n",
    "\n",
    "### Research Questions\n",
    "\n",
    "- How does the **gender of a movie director** influence the portrayal of women in cinema?\n",
    "\n",
    "- What are the **key female stereotypes** in movies?\n",
    "\n",
    "- Are female director **better than men** at depicting women in movies? \n",
    "\n",
    "### Tools, Libraries, and Datasets\n",
    "\n",
    "#### Tools and Libraries\n",
    "- **Python Libraries**:\n",
    "  - **Pandas**\n",
    "  - **Numpy**\n",
    "  - **Matplotlib**\n",
    "  - **Seaborn** (display graphs)\n",
    "  - **json** (clustering movie languages, genres and countries)\n",
    "  - **tqdm** (progression bar when running functions)\n",
    "  - **collections** (Counter)\n",
    "  - [**Hugging Face’s transformers library**](https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2) (sentiment analysis)\n",
    "  \n",
    "- **Visualization**: Interactive visualization libraries (to be determined)\n",
    "\n",
    "#### Main dataset\n",
    "- **CMU Movie Summaries Dataset**: contains the following files:\n",
    "  - **characters_metadata.tsv**  \n",
    "  - **movie_metadata.tsv**  \n",
    "  - **name_clusters.txt**  \n",
    "  - **plot_summaries.txt**  \n",
    "  - **tvtropes.clusters.txt**  \n",
    "\n",
    "#### Proposed additional datasets\n",
    "- [**IMDb Ratings**](https://datasets.imdbws.com/):\n",
    "  - provides movie ratings data\n",
    "  - reduces the initial dataset size by only keeping movies whose ratings are available\n",
    "- [**TMDB Ratings**](https://www.kaggle.com/datasets/juzershakir/tmdb-movies-dataset):\n",
    "  - provides box office and budget data\n",
    "- [**Bechdel Test API**](https://bechdeltest.com/api/v1/doc): This dataset\n",
    "  - provides Bechdel Test result ('rating') for a group of movies.\n",
    "  - drastically reduces primary dataset size\n",
    "  - essential for assessing gender interaction trends and understanding the accuracy of the Bechdel Test as a predictor of gender equality in film.\n",
    "- [**Gender by name - UCI** :](https://archive.ics.uci.edu/dataset/591/gender+by+name)\n",
    "  - provides a wide range of first names and associated gender\n",
    "  - used to recover missing gender in the character_metadata.tsv file\n",
    "  - indirectly helps to analyze how genders correlate with character types\n",
    "\n",
    "ORGA REPO\n",
    "\n",
    "Our repository is organized the following way :\n",
    "> data\n",
    " > processed\n",
    "  > transitionary\n",
    "  movies_complete_csv\n",
    " > raw\n",
    "   \n",
    "> src\n",
    " > data\n",
    "  > external_data\n",
    "  data_cleaner.py\n",
    "  data_loader.py\n",
    "  data_transformer.py\n",
    " > models\n",
    " > utils\n",
    "  models.py\n",
    "  train_model.py\n",
    "\n",
    ".gitignore\n",
    "pip_requirements.text\n",
    "README.md\n",
    "results.ipynb\n",
    "\n",
    "The first folder « data » contains the majority of the data used for our analysis. It is separated into two distinct folders : « processed » which contains processed and filtered dataframes, ready to be used, and « raw » which constitute the initial database, uncleaned. The majority of dataframes contained within « processed » are located in a particular folder called « transitionary ». They won’t be used as such when performing analysis, but were shaped and transformed to create the csv file movies_complete.csv.\n",
    "\n",
    "Then, the folder « src » contains itself a folder « data », as well as « models » and « utils ».\n",
    "First things first, « data » contains the external_data folder that groups all csv files that could not be imported into GitHub as too heavy. This folder is specified in the file .gitignore for logical reasons. Then, « data » contains 3 .py files :\n",
    " • data_cleaner.py helps us clean specific portions of the dataframes, such as the release date of the movies which was initially either in a DateTime format or displayed as Year.\n",
    " • data_loader.py gathering functions allowing us to load data from external datasets and loading files while running Exceptions\n",
    " • data_transformer.py in which we preprocess, filter and clean raw and external datasets\n",
    "\n",
    "« models » contain the fabulous Machine Learning model of Mahlia. While functions within evaluate_model.py literally evaluates the ML model created and contained in models.py, train_model.py once again literally trains the model evaluated.\n",
    "\n",
    "The folder « utils » contains the inevitable « pycache » folder, as well as methods.py which gathers functions that process and shape data from movies_complete_df to plug it directly into the plotting functions gathered in visualization.py.\n",
    "\n",
    "Do we still need to present the following files : .gitignore, pip_requirements.text and README.md ? These three files are inevitable in any GitHub repository and permit us to « hide » certain files or folders from GitHub, install specific versions of libraries and the README.md mmh, let me think. \n",
    "\n",
    "Lastly, the file results.ipynb contains all of our greatest analysis performed on the numerous datasets collected. Graphs functions have been written and artistically designed by the greatest artistic directors of the ADApocalypse group, and explained by statisticiens.\n",
    "\n",
    "### Repository Structure \n",
    "\n",
    "This project is structured as follows:\n",
    "\n",
    "```sh\n",
    "├── .gitignore\n",
    "├── data                                # data sources\n",
    "│   ├── (processed)\n",
    "│   │   ├── (characters_metadata.csv)    # pre-filtered youniverse files\n",
    "│   │   ├── (imdb_ratings.csv)\n",
    "│   │   ├── (movies_director.csv)\n",
    "│   │   ├── (movies_directors_combined.csv)\n",
    "│   │   ├── (movies_metadata_success.csv)\n",
    "│   │   ├── (movies_metadata.csv)\n",
    "│   │   └── (original)                  # original youniverse dataset\n",
    "│   │       ├── (df_channels_en.tsv)\n",
    "│   │       ├── (df_timeseries_en.tsv)\n",
    "│   │       ├── (youtube_comments.tsv)\n",
    "│   │       └── (yt_metadata_en.jsonl)\n",
    "│   ├── (raw)\n",
    "│   ├── games.csv\n",
    "│   └── word_alpha.txt      \n",
    "├── notebooks                          \n",
    "│   ├── results.ipynb                   # main analysis notebook\n",
    "│   └── prefiltering.ipynb              # data prefiltering notebook\n",
    "├── src                                         \n",
    "│   └── utils.py                        # utility functions\n",
    "├── requirements.txt                    # pip requirements file\n",
    "└── README.md\n",
    "```\n",
    "\n",
    "### Methods\n",
    "\n",
    "### Management of External Datasets\n",
    "\n",
    "Several large datasets essential for the MADAME project were excluded from the Git repository and added to `.gitignore`. These files are located in the `src/data/external_data` directory and need to be downloaded manually from their respective sources. Below is the list of datasets used:\n",
    "\n",
    "1. **`title.basics.tsv`**  \n",
    "   - **Source**: IMDB database  \n",
    "   - **Description**: Contains metadata about films, including titles, release years, and genres.  \n",
    "\n",
    "2. **`title.ratings.tsv`**  \n",
    "   - **Source**: IMDB database  \n",
    "   - **Description**: Provides information about movie ratings and vote counts.  \n",
    "\n",
    "3. **`TMDB_movie_dataset_v11.csv`**  \n",
    "   - **Source**: [Kaggle](https://www.kaggle.com/)  \n",
    "   - **Description**: A comprehensive dataset with detailed information about movies, such as budgets, revenues, and more.  \n",
    "\n",
    "4. **`film_tropes.csv`**  \n",
    "   - **Source**: [TV Tropes Repository](https://github.com/dhruvilgala/tvtropes?tab=readme-ov-file)  \n",
    "   - **Description**: Includes data on film tropes and their associations.  \n",
    "\n",
    "5. **`genderedness_filter.csv`**  \n",
    "   - **Source**: [TV Tropes Repository](https://github.com/dhruvilgala/tvtropes?tab=readme-ov-file)  \n",
    "   - **Description**: Provides insights into gender-related classifications of tropes.  \n",
    "\n",
    "#### Data Handling & preprocessing\n",
    "- **Data Wrangling**: extraction, cleaning and standardization of the data\n",
    "- Focus on aligning the datasets with respect to key attributes such as character tv tropes, character and actors respective names and genders, plots, and movie genres\n",
    "- Data filtering to comply with the proposed additional datasets and assure compatibility across sources + reduction of the usable data size and \n",
    "- Data clustering\n",
    "DETAILLER \n",
    "\n",
    "#### Data Visualization\n",
    "- **Univariable Analysis**: use of data visualisation techniques (histograms, box and scatter plots...) to conduct a graphical analysis of the gender distribution of characters and actors.\n",
    "\n",
    "- **Multivariable Analysis**: further analysis to identify relationships between various factors (e.g. the presence of female characters, movie ratings, box office performance, etc...)\n",
    "\n",
    "#### Data Description\n",
    "Robust statistical methods is used to evaluate correlations, distributions, and outliers in the data\n",
    "Quels tests ont été utilisés ?\n",
    "DETAILLER\n",
    "\n",
    "#### 5. Learning From Data\n",
    "- **Machine Learning Techniques**: ML methods (which ones) were employed to create a model for classifying films based on their gender representation and to predict whether a film will pass or fail the Bechdel Test. - Accuracy of 70%\n",
    "\n",
    "#### 6. Sentiment Analysis\n",
    "The sentiment of character descriptions and plot summaries will be analyzed using pre-trained sentiment models to assess how women’s roles are portrayed physically and emotionally.\n",
    "\n",
    "### Timeline\n",
    "\n",
    "**Week 1 to 9**:\n",
    "  - Individual exploration and data wrangling\n",
    "  - Preliminary analysis on the CMU Movie Summaries dataset\n",
    "  - Definition of project objectives, allocation of tasks and delineation of additional datasets\n",
    "\n",
    "**Week 10**:  \n",
    "  - Further data wrangling\n",
    "  - Analysis on the preprocessed data\n",
    "\n",
    "**Week 11**:  \n",
    "  - Team collaboration in order to refine data handling steps\n",
    "  - Work on initial visualizations and analysis \n",
    "\n",
    "**Week 12**:  \n",
    "  - Finalization of data analysis and visualizations.\n",
    "  - Sentiment analysis on character descriptions and plot summaries\n",
    "  - Website creation, using svelte UI framework \n",
    "  - Data and visualization formatting in json\n",
    "\n",
    "**Week 13**:  \n",
    "  - Focus on predictive modeling and refining the analysis based on feedback\n",
    "  - Further work on web interface structure, improvement of interactiveness \n",
    "  - Further work on data and visualization formatting in json\n",
    "  - Repository ‘cleaning’ (restructuring git and organizing functions, results files etc…) \n",
    "  - Storytelling writing \n",
    "DÉTAILLER \n",
    "\n",
    "**Week 14**:  \n",
    "  - Completion of the final project notebook\n",
    "  - Final work on data and visualization formatting in json \n",
    "  - Storytelling implementation on the webpage \n",
    "  - Styling and design of the webpage\n",
    "  - Editing the readme \n",
    "  - Content proofreading \n",
    "DÉTAILLER \n",
    "\n",
    "### Organization within the Team\n",
    "\n",
    "- **Coralie**: \"movie metadata\" analysis, website interface management, formatting data and visualizations in json\n",
    "\n",
    "- **Juliette**: \"movie metadata\" analysis, data preprocessing, project timeline management, cleaning of the repository\n",
    "\n",
    "- **Mahlia**: \"character metadata\" analysis, ML Bechdel model,  data preprocessing, cleaning of the repository \n",
    "\n",
    "- **Maximilien**: \"tvtropes\" and \"plot_summaries\" analysis, \"transformer\" model analysis\n",
    "\n",
    "- **Pernelle**: \"character metadata\" analysis, storytelling writing, graphic design of the website page \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.8 ('ada')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2ddbd0b842a978e03471eb3a4ae18fdd24eb8ad76bdab23b363108c4c8f6a59c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
